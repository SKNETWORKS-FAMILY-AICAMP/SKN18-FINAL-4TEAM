"""
stt_client.py

WhisperLiveKitë¥¼ ì§ì ‘ Python ì½”ë“œì—ì„œ í˜¸ì¶œí•´ì„œ
- PCM ìŒì„± ë°”ì´íŠ¸ë¥¼ ë„£ìœ¼ë©´
- ë§ˆì§€ë§‰ FrontData ê¸°ì¤€ì˜ `lines` (list[Line]) ê¹Œì§€ë§Œ ë§Œë“¤ì–´ì„œ
  ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ ì£¼ëŠ” ê°„ë‹¨ ëž˜í¼ + (ì„ íƒ) ê°€ë²¼ìš´ NLP ë³´ì •.
"""

import asyncio
import os
from typing import Any, Dict, List, Optional

from whisperlivekit import AudioProcessor, TranscriptionEngine  # basic_serverì™€ ë™ì¼í•œ import

#from openai import OpenAI  # ë§¤ìš° ì•½í•œ ì˜ë¯¸ ë³´ì •ì— ì‚¬ìš© (ì„ íƒ)


class STTClient:
    """
    WhisperLiveKit ê¸°ë°˜ STT í´ë¼ì´ì–¸íŠ¸.

    - ìµœì´ˆ í˜¸ì¶œ ì‹œ TranscriptionEngineì„ í•œ ë²ˆë§Œ ë„ì›Œì„œ ìž¬ì‚¬ìš©
    - audio_bytes(PCM)ë¥¼ ë„£ìœ¼ë©´ ë§ˆì§€ë§‰ FrontData.lines ë¥¼ ê·¸ëŒ€ë¡œ ëŒë ¤ì¤Œ
    - (ì˜µì…˜) ê° line["text"]ì— ëŒ€í•´ ì•½í•œ ì˜ë¯¸ ë³´ì •(NLP) ìˆ˜í–‰
    """

    def __init__(
        self,
        *,
        model_size: str = "base",
        language: str = "auto",
        backend: str = "auto",
        device: Optional[str] = None,
        enable_diarization: bool = False,
        enable_translation: bool = False,
        enable_repair: bool = False,    # âœ… NLP ë³´ì • ì¼œê¸°/ë„ê¸°
        **extra_engine_kwargs: Any,
    ) -> None:
        """
        STTClient ì´ˆê¸°í™”.

        í•„ìš”í•˜ë©´ TranscriptionEngineì— ë„˜ê¸¸ ì˜µì…˜ë“¤ì„ ì—¬ê¸°ì„œ ì¡°ì •í•˜ë©´ ë¨.
        """
        self.enable_repair = enable_repair

        # TranscriptionEngine ì— ë„˜ê¸¸ ì˜µì…˜ ëª¨ìŒ (core.py ì°¸ê³ , ì¼ë¶€ë§Œ ì‚¬ìš©)
        self._engine_kwargs: Dict[str, Any] = {
            "backend": backend,
            "model_size": model_size,
            "lan": language,
            "direct_english_translation": False,
            "pcm_input": True,          # âœ… ìš°ë¦¬ëŠ” PCM ë°”ì´íŠ¸ë¥¼ ì§ì ‘ ë„£ì„ ê²ƒì´ë¯€ë¡œ í•­ìƒ True
            "transcription": True,
            "diarization": enable_diarization,
        }

        if enable_translation:
            self._engine_kwargs["translation"] = True

        self._engine_kwargs.update(extra_engine_kwargs)

        self._engine: Optional[TranscriptionEngine] = None
        self._lock = asyncio.Lock()

        # NLP ë³´ì •ì„ ì“¸ ê²½ìš°ì—ë§Œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
        

    async def _get_engine(self) -> TranscriptionEngine:
        """
        TranscriptionEngineì„ lazy init í•´ì„œ ìž¬ì‚¬ìš©.
        """
        async with self._lock:
            if self._engine is None:
                self._engine = TranscriptionEngine(**self._engine_kwargs)
            return self._engine

    # -------------------------
    #  NLP ë³´ì • ê´€ë ¨ ë‚´ë¶€ í•¨ìˆ˜ë“¤
    # -------------------------

    

    def _repair_lines(self, lines: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        return lines

    # -------------------------
    #  STT ë©”ì¸ ë¡œì§
    # -------------------------

    async def _run_once_pcm(self, pcm_bytes: bytes) -> List[Dict[str, Any]]:
        """
        í•œ ë²ˆì˜ STT ì„¸ì…˜:
        - AudioProcessor ìƒì„±
        - create_tasks()ë¡œ ë‚´ë¶€ ìž‘ì—…(task) ì‹œìž‘
        - pcm_bytesë¥¼ chunk ë‹¨ìœ„ë¡œ process_audio()ë¡œ í˜ë ¤ë³´ëƒ„
        - ë§ˆì§€ë§‰ì— ë¹ˆ ë°”ì´íŠ¸ë¥¼ ë³´ë‚´ stop
        - ë™ì‹œì— results_formatter() (create_tasksì˜ ë°˜í™˜ê°’)ì„ ì†Œë¹„í•˜ë©´ì„œ
          ê°€ìž¥ ë§ˆì§€ë§‰ FrontDataì˜ lines ë¥¼ ê¸°ì–µí–ˆë‹¤ê°€ ë°˜í™˜
        """
        engine = await self._get_engine()
        audio_processor = AudioProcessor(transcription_engine=engine)

        results_generator = await audio_processor.create_tasks()

        bytes_per_sec = getattr(audio_processor, "bytes_per_sec", 32000)
        chunk_size = max(bytes_per_sec // 4, 1)  # ëŒ€ëžµ 0.25ì´ˆ ë‹¨ìœ„

        last_lines: List[Dict[str, Any]] = []

        async def _feed_audio() -> None:
            for i in range(0, len(pcm_bytes), chunk_size):
                chunk = pcm_bytes[i : i + chunk_size]
                await audio_processor.process_audio(chunk)
            # ë¹ˆ ë°”ì´íŠ¸ë¥¼ ë³´ë‚´ì„œ "ì´ì œ ëë‚¬ë‹¤" ì‹ í˜¸ ë³´ë‚´ê¸°
            await audio_processor.process_audio(b"")

        async def _consume_results() -> None:
            nonlocal last_lines
            async for front_data in results_generator:
                data = front_data.to_dict()
                if "lines" in data:
                    last_lines = data["lines"]

        try:
            await asyncio.gather(_feed_audio(), _consume_results())
        finally:
            await audio_processor.cleanup()

        # ðŸ”§ ì—¬ê¸°ì—ì„œ NLP ë³´ì • í•œ ë²ˆ íƒœìš´ë‹¤
        
        return last_lines

    async def transcribe_pcm(self, pcm_bytes: bytes) -> List[Dict[str, Any]]:
        """
        16kHz mono s16le PCM ë°”ì´íŠ¸ë¥¼ ìž…ë ¥í•˜ë©´
        WhisperLiveKitê°€ êµ¬ì„±í•œ ë§ˆì§€ë§‰ FrontData ê¸°ì¤€ì˜
        list[Line] (dict í˜•íƒœ) ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•œë‹¤.
        (ì˜µì…˜) textëŠ” ì•½í•œ ì˜ë¯¸ ë³´ì •ì„ ê±°ì¹œ ìµœì¢… ë²„ì „ì¼ ìˆ˜ ìžˆë‹¤.
        """
        return await self._run_once_pcm(pcm_bytes)

    def transcribe_pcm_sync(self, pcm_bytes: bytes) -> List[Dict[str, Any]]:
        return asyncio.run(self.transcribe_pcm(pcm_bytes))

#-----------------------
# agent.py 
#-----------------------

"""
handle_requestëŠ” ê¸°ì¡´ ë¡œì§ì—ì„œ ë³€ê²½ë˜ì—ˆìœ¼ë©°, Evaluator ê²€ì¦ ë¡œì§ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

def handle_request(payload: Dict[str, Any], store=None):
    """
    Main Agent ì‹¤í–‰ -> (í•„ìš”ì‹œ) Evaluator ê²€ì¦ -> ê²°ê³¼ ë°˜í™˜
    """
    # 1. Context Pack êµ¬ì„± (ê¸°ì¡´ ë¡œì§)
    context_pack = build_context_pack(payload)
    
    # 2. í•„ìˆ˜ í”„ë¡œí•„ ê²€ì¦ (ê¸°ì¡´ ë¡œì§)
    missing = missing_profile_fields(context_pack["profile"])
    if missing:
        ask = f"í”„ë¡œí•„ ë³´ì™„ì´ í•„ìš”í•´ìš”. {', '.join(missing)} ê°’ì„ ì•Œë ¤ì£¼ì‹œë©´ ê³„íšì„ ì„¸ìš¸ê²Œìš”."
        return {"messages": [AIMessage(content=ask)], "agent": "main", "context": context_pack}

    # 3. ì—ì´ì „íŠ¸ ì¤€ë¹„
    user_id = context_pack["request"].get("user_id", "unknown")
    main_agent = create_main_agent(user_id=user_id, store=store)
    
    # ì´ˆê¸° ì…ë ¥ ìƒíƒœ ì„¤ì •
    current_state = {
        **context_pack,
        "messages": [HumanMessage(content=context_pack["request"].get("message", ""))]
    }

    # -------------------------------------------------------
    # [ì•ˆì „ ì¥ì¹˜ 1] í‰ê°€ê°€ í•„ìš”í•œ ì˜ë„ì¸ì§€ í™•ì¸ (ì¡ë‹´ì€ íŒ¨ìŠ¤)
    # -------------------------------------------------------
    intent = context_pack["request"].get("intent", "")
    should_evaluate = intent in ["plan", "research"]  # í‰ê°€í•  Intent ëª©ë¡
    
    # í‰ê°€ê°€ í•„ìš” ì—†ë‹¤ë©´ ë°”ë¡œ ì‹¤í–‰ í›„ ë¦¬í„´ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
    if not should_evaluate:
        return main_agent.invoke(current_state)

    # -------------------------------------------------------
    # [Loop] í‰ê°€ ë° ì¬ì‹œë„ ë¡œì§
    # -------------------------------------------------------
    evaluator = evaluator_agent()
    MAX_RETRIES = 2
    
    # ìµœì¢… ë°˜í™˜ê°’ì„ ë‹´ì„ ë³€ìˆ˜ (ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ì‹œë„ë¼ë„ ë°˜í™˜í•˜ê¸° ìœ„í•´)
    last_response = None 

    for attempt in range(MAX_RETRIES + 1):
        # (A) Main Agent ì‹¤í–‰
        # invoke ì‹œ ë§ˆë‹¤ ì´ì „ ëŒ€í™”(ì¬ì‹œë„ í¬í•¨)ê°€ current_state['messages']ì— ëˆ„ì ë˜ì–´ ì „ë‹¬ë¨
        response = main_agent.invoke(current_state)
        last_response = response 

        # (B) Evaluator ì‹¤í–‰
        # Main Agentì˜ ì‘ë‹µì„ í‰ê°€ìê°€ ì½ì„ ìˆ˜ ìˆë„ë¡ ì „ë‹¬
        eval_context = {**context_pack, "latest_response": response}
        
        try:
            eval_result = evaluator.invoke(eval_context)
            verdict = eval_result["evaluation"]
        except Exception as e:
            # [ì•ˆì „ ì¥ì¹˜ 2] í‰ê°€ê¸° ì—ëŸ¬ ì‹œ Main ê²°ê³¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì‚¬ìš©ì ê²½í—˜ ë³´í˜¸)
            print(f"âš ï¸ Evaluator Error: {e}")
            return response

        # (C) PASS íŒì • ì‹œ ì¦‰ì‹œ ë¦¬í„´
        if verdict["decision"] == "PASS":
            response["evaluation_meta"] = verdict
            return response
            
        # (D) REJECT íŒì • ì‹œ ì¬ì‹œë„ ì¤€ë¹„
        if attempt < MAX_RETRIES:
            print(f"ğŸ”„ ë°˜ë ¤ë¨ ({attempt+1}/{MAX_RETRIES}): {verdict['violation']}")
            
            feedback_msg = (
                f"[System Notice] ìƒì„±ëœ ê³„íšì´ í’ˆì§ˆ ê¸°ì¤€ì— ë¯¸ë‹¬í•˜ì—¬ ì¬ì‘ì„±í•©ë‹ˆë‹¤.\n"
                f"- ë¬¸ì œì : {verdict['violation']}\n"
                f"- ìˆ˜ì • ì§€ì¹¨: {verdict['feedback']}"
            )
            
            # [ì•ˆì „ ì¥ì¹˜ 3] ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
            # Main Agentê°€ ë±‰ì€ ê²°ê³¼(response['messages'])ì™€ í”¼ë“œë°±ì„
            # ë‹¤ìŒ í„´ì˜ ì…ë ¥(current_state['messages'])ì— ì¶”ê°€
            if "messages" in response:
                current_state["messages"].extend(response["messages"])
            current_state["messages"].append(HumanMessage(content=feedback_msg))
            
        else:
            # ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ -> ì‹¤íŒ¨í–ˆì§€ë§Œ ì¼ë‹¨ ê²°ê³¼ ë°˜í™˜ (Warning í¬í•¨)
            response["evaluation_meta"] = verdict
            response["warning"] = "ê²€ì¦ ê¸°ì¤€ì„ ì™„ì „íˆ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            return response

    return last_response


def evaluator_agent():
    """ê²°ê³¼ë¬¼ í’ˆì§ˆ ê²€ì¦ ë° ì •í•©ì„± ì²´í¬ ì—ì´ì „íŠ¸."""

    # í‰ê°€ ê¸°ì¤€ì´ ëª…ì‹œëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    EVALUATOR_SYSTEM_PROMPT = """
    ë‹¹ì‹ ì€ ì—„ê²©í•œ 'AI ì½”ì¹­ í’ˆì§ˆ ê´€ë¦¬ì(QA)'ì…ë‹ˆë‹¤.
    Main Agentê°€ ìƒì„±í•œ ê³„íšì´ë‚˜ ë‹µë³€ì´ ì‚¬ìš©ìì˜ í”„ë¡œí•„ê³¼ ì œì•½ì¡°ê±´ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.

    [ê²€ì¦ ê¸°ì¤€]
    1. **í”„ë¡œí•„ ì •í•©ì„±**: 
    - ì‚¬ìš©ìì˜ 'skill_level'ì— ë§ëŠ” ë‚œì´ë„ì¸ê°€?
    - 'weekly_hours'(ì£¼ê°„ ê°€ìš© ì‹œê°„) ë‚´ì— ì†Œí™” ê°€ëŠ¥í•œ ë¶„ëŸ‰ì¸ê°€?
    2. **ìš”êµ¬ì‚¬í•­ ì¶©ì¡±**:
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸(Message)ê³¼ ì˜ë„(Intent)ë¥¼ ì •í™•íˆ í•´ê²°í–ˆëŠ”ê°€?
    - í•„ìˆ˜ í•„ë“œ(week_goals, focus_areas ë“±)ê°€ ëˆ„ë½ë˜ì§€ ì•Šì•˜ëŠ”ê°€?
    3. **ë…¼ë¦¬ì  ì™„ê²°ì„±**:
    - ëª©í‘œ(Goal)ì™€ ì„¸ë¶€ ì•¡ì…˜(Action)ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ê°€?
    - ë‚ ì§œë‚˜ ê¸°í•œì´ í˜„ì‹¤ì ì¸ê°€?

    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í¬ë§·ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    """

    evaluator_prompt = ChatPromptTemplate.from_messages([
        ("system", EVALUATOR_SYSTEM_PROMPT),
        ("human", 
        "--- [ì‚¬ìš©ì í”„ë¡œí•„] ---\n{profile}\n\n"
        "--- [ì‚¬ìš©ì ìš”ì²­] ---\n{request}\n\n"
        "--- [Main Agent ë‹µë³€] ---\n{agent_output}\n\n"
        "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í‰ê°€(JSON)ë¥¼ ìˆ˜í–‰í•´:"
        )
    ])

    def run(context: Dict[str, Any]) -> Dict[str, Any]:
        # Main Agentì˜ ì¶œë ¥ë¬¼ ì¶”ì¶œ (context['messages']ì˜ ë§ˆì§€ë§‰ AIMessage í˜¹ì€ íŠ¹ì • í‚¤)
        # ì—¬ê¸°ì„œëŠ” contextì— 'latest_response' í˜¹ì€ Main Agentì˜ ê²°ê³¼ê°€ ë³‘í•©ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        agent_output = context.get("latest_response", "")
        
        # ë§Œì•½ Main Agentê°€ êµ¬ì¡°í™”ëœ planì„ ë±‰ì—ˆë‹¤ë©´ ê·¸ê±¸ ê²€ì¦
        if isinstance(agent_output, dict) and "plan" in agent_output:
            agent_output_str = str(agent_output["plan"])
        elif isinstance(agent_output, AIMessage):
            agent_output_str = agent_output.content
        else:
            agent_output_str = str(agent_output)

        inputs = {
            "profile": context.get("profile", {}),
            "request": context.get("request", {}),
            "agent_output": agent_output_str
        }

        try:
            # LLM í˜¸ì¶œ (EvaluatorëŠ” ë…¼ë¦¬ë ¥ì´ ì¤‘ìš”í•˜ë¯€ë¡œ Mainê³¼ ê°™ì€ ê³ ì„±ëŠ¥ ëª¨ë¸ ê¶Œì¥)
            verdict: EvaluationVerdict = (evaluator_prompt | LLM | evaluator_parser).invoke(inputs)
            verdict_dict = verdict.model_dump()
        except Exception as e:
            # íŒŒì‹± ì—ëŸ¬ ì‹œ ì•ˆì „í•˜ê²Œ PASS ì²˜ë¦¬í•˜ê±°ë‚˜ ì—ëŸ¬ ë¡œê·¸ ë°˜í™˜
            verdict_dict = {
                "decision": "PASS", 
                "score": 50, 
                "feedback": f"í‰ê°€ ì¤‘ ì—ëŸ¬ ë°œìƒ(ìë™ í†µê³¼): {str(e)}", 
                "violation": None
            }

        return {
            "agent": "evaluator",
            "evaluation": verdict_dict,
            "context": context
        }

    return RunnableLambda(run)


#-----------------------
# models.py
#-----------------------
from typing import Literal, Optional
from langchain_core.pydantic_v1 import BaseModel, Field

class EvaluationVerdict(BaseModel):
    decision: Literal["PASS", "REJECT"] = Field(..., description="í†µê³¼ ì—¬ë¶€")
    score: int = Field(..., description="0~100 ì‚¬ì´ì˜ í’ˆì§ˆ ì ìˆ˜")
    feedback: Optional[str] = Field(None, description="REJECTì¼ ê²½ìš° ìˆ˜ì • ì§€ì¹¨, PASSë©´ ì¹­ì°¬ì´ë‚˜ ì½”ë©˜íŠ¸")
    violation: Optional[str] = Field(None, description="ìœ„ë°˜í•œ ì œì•½ì¡°ê±´ì´ ìˆë‹¤ë©´ ëª…ì‹œ (ì˜ˆ: ì‹œê°„ ì´ˆê³¼, ë ˆë²¨ ë¶ˆì¼ì¹˜)")

# í‰ê°€ì ì „ìš© íŒŒì„œ
evaluator_parser = JsonOutputParser(pydantic_object=EvaluationVerdict)


# ê¸°ì¡´ ë¡œì§ì—ì„œ ì¡°ê¸ˆ ë³€ê²½ë¨
class UserNextAction(models.Model):
    id = models.BigAutoField(primary_key=True)
    user = models.ForeignKey(User, on_delete=models.CASCADE, db_column="user_id")
    action_id = models.CharField(max_length=100)
    title = models.CharField(max_length=255)
    description = models.TextField(null=True, blank=True)
    due = models.DateTimeField(null=True, blank=True)
    priority = models.CharField(max_length=20, null=True, blank=True)
    status = models.CharDateTimeField(auto_now_add=True)
    updated_at = modelField(max_length=20, null=True, blank=True)  # todo/doing/done
    created_at = models.s.DateTimeField(auto_now=True)

    class Meta:
        db_table = "user_next_actions"
        constraints = [
            models.UniqueConstraint(fields=["user", "action_id"], name="uq_user_action")
        ]
        indexes = [
            models.Index(fields=["user", "status"], name="idx_next_actions_status"),
        ]


#-----------------------
# views.py
#-----------------------
from .agent_service import handle_request 

class ChatView(APIView):
    def post(self, request):
        payload = request.data
        
        # ì—¬ê¸°ì„œ 'handle_request'ë¥¼ í˜¸ì¶œí•˜ë©´
        # ë‚´ë¶€ì ìœ¼ë¡œ í‰ê°€ ë£¨í”„ê°€ ë‹¤ ëŒì•„ê°„ ë’¤ì˜ 'ìµœì¢… ê²°ê³¼'ë§Œ ë¦¬í„´ë©ë‹ˆë‹¤.
        response_data = handle_request(payload) 
        
        return Response(response_data)
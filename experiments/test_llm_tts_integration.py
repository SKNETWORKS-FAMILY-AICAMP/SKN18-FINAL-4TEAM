import os
import time
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ê³µí†µ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì •ì¤‘í•œ ì½”ë”© ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
- ì¹œì ˆí•˜ì§€ë§Œ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ê¸°ìˆ  ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”
- ì‘ì‹œìë¥¼ ê²©ë ¤í•˜ë©´ì„œ í”¼ë“œë°±í•˜ì„¸ìš”
- 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”"""

# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
TEST_QUESTION = "í•´ì‹œë§µì˜ ì‹œê°„ë³µì¡ë„ì™€ ì¶©ëŒ ì²˜ë¦¬ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."

class PerformanceMetrics:
    """ì„±ëŠ¥ ì¸¡ì • í—¬í¼"""
    
    def __init__(self, method_name):
        self.method_name = method_name
        self.llm_time = 0
        self.tts_time = 0
        self.total_time = 0
        self.first_audio_time = 0  # ì²« ìŒì„±ê¹Œì§€ ê±¸ë¦° ì‹œê°„
        self.audio_files = []
        
    def print_results(self):
        print(f"\n{'='*70}")
        print(f"ğŸ“Š [{self.method_name}] ì„±ëŠ¥ ê²°ê³¼")
        print(f"{'='*70}")
        print(f"  LLM ì‘ë‹µ ì‹œê°„:        {self.llm_time:.2f}ì´ˆ")
        print(f"  TTS ìƒì„± ì‹œê°„:        {self.tts_time:.2f}ì´ˆ")
        print(f"  ì´ ì†Œìš” ì‹œê°„:         {self.total_time:.2f}ì´ˆ")
        if self.first_audio_time > 0:
            print(f"  ì²« ìŒì„±ê¹Œì§€ ì‹œê°„:     {self.first_audio_time:.2f}ì´ˆ â­")
        print(f"  ìƒì„±ëœ ìŒì„± íŒŒì¼ ìˆ˜:  {len(self.audio_files)}ê°œ")
        print(f"{'='*70}\n")


# ============================================================================
# ë°©ë²• 1: ê¸°ë³¸ ë°©ì‹ (ì „ì²´ ë‹µë³€ â†’ TTS)
# ============================================================================

def method1_basic(question, voice="nova"):
    """ë°©ë²• 1: ê¸°ë³¸ - LLM ì „ì²´ ë‹µë³€ í›„ TTS"""
    
    metrics = PerformanceMetrics("ë°©ë²• 1: ê¸°ë³¸")
    
    print(f"\n{'='*70}")
    print(f"ë°©ë²• 1: ê¸°ë³¸ ë°©ì‹ í…ŒìŠ¤íŠ¸")
    print(f"{'='*70}")
    print(f"ì§ˆë¬¸: {question}\n")
    
    total_start = time.time()
    
    # 1. LLM ë‹µë³€ ìƒì„±
    print("ğŸ¤– LLM ë‹µë³€ ìƒì„± ì¤‘...")
    llm_start = time.time()
    
    llm_response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": question}
        ],
        temperature=0.7,
        max_tokens=300
    )
    
    answer_text = llm_response.choices[0].message.content
    metrics.llm_time = time.time() - llm_start
    
    print(f"âœ… LLM ì™„ë£Œ ({metrics.llm_time:.2f}ì´ˆ)")
    print(f"\në©´ì ‘ê´€: {answer_text}\n")
    
    # 2. TTS ë³€í™˜
    print("ğŸ”Š ìŒì„± ìƒì„± ì¤‘...")
    tts_start = time.time()
    
    tts_response = client.audio.speech.create(
        model="tts-1-hd",
        voice=voice,
        input=answer_text,
        speed=1.0
    )
    
    metrics.tts_time = time.time() - tts_start
    
    filename = f"method1_basic_{int(time.time())}.mp3"
    tts_response.stream_to_file(filename)
    metrics.audio_files.append(filename)
    
    print(f"âœ… TTS ì™„ë£Œ ({metrics.tts_time:.2f}ì´ˆ)")
    print(f"ğŸ“ ì €ì¥: {filename}")
    
    metrics.total_time = time.time() - total_start
    metrics.first_audio_time = metrics.total_time
    
    metrics.print_results()
    return metrics


# ============================================================================
# ë°©ë²• 2: ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë°
# ============================================================================

def split_sentences(text):
    """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬"""
    sentences = re.split(r'([.!?]\s+)', text)
    result = []
    for i in range(0, len(sentences)-1, 2):
        if i+1 < len(sentences):
            sentence = (sentences[i] + sentences[i+1]).strip()
            if sentence:
                result.append(sentence)
    # ë§ˆì§€ë§‰ ë¬¸ì¥ ì²˜ë¦¬
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        result.append(sentences[-1].strip())
    return result

def method2_sentence_streaming(question, voice="nova"):
    """ë°©ë²• 2: ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° - LLM ìŠ¤íŠ¸ë¦¼ + ë¬¸ì¥ë³„ ì¦‰ì‹œ TTS"""
    
    metrics = PerformanceMetrics("ë°©ë²• 2: ë¬¸ì¥ ìŠ¤íŠ¸ë¦¬ë°")
    
    print(f"\n{'='*70}")
    print(f"ë°©ë²• 2: ë¬¸ì¥ ë‹¨ìœ„ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸")
    print(f"{'='*70}")
    print(f"ì§ˆë¬¸: {question}\n")
    
    total_start = time.time()
    
    # LLM ìŠ¤íŠ¸ë¦¬ë°
    print("ğŸ¤– LLM ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘...\n")
    llm_start = time.time()
    
    stream = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": question}
        ],
        stream=True,
        temperature=0.7,
        max_tokens=300
    )
    
    full_response = ""
    sentence_buffer = ""
    sentence_count = 0
    first_audio_generated = False
    
    print("ë©´ì ‘ê´€: ", end="", flush=True)
    
    for chunk in stream:
        if chunk.choices[0].delta.content:
            content = chunk.choices[0].delta.content
            print(content, end="", flush=True)
            
            full_response += content
            sentence_buffer += content
            
            # ë¬¸ì¥ ë ê°ì§€
            if re.search(r'[.!?]\s*$', sentence_buffer.strip()):
                sentence = sentence_buffer.strip()
                
                if not first_audio_generated:
                    metrics.llm_time = time.time() - llm_start
                
                # ì¦‰ì‹œ TTS ìƒì„±
                tts_start = time.time()
                
                tts_response = client.audio.speech.create(
                    model="tts-1",  # ì†ë„ë¥¼ ìœ„í•´ tts-1
                    voice=voice,
                    input=sentence,
                    speed=1.0
                )
                
                tts_duration = time.time() - tts_start
                metrics.tts_time += tts_duration
                
                sentence_count += 1
                filename = f"method2_sentence_{sentence_count}_{int(time.time())}.mp3"
                tts_response.stream_to_file(filename)
                metrics.audio_files.append(filename)
                
                if not first_audio_generated:
                    metrics.first_audio_time = time.time() - total_start
                    first_audio_generated = True
                    print(f"\n\nâš¡ ì²« ìŒì„± ìƒì„±! ({metrics.first_audio_time:.2f}ì´ˆ)")
                
                print(f"\n  â†’ ë¬¸ì¥ {sentence_count} ìŒì„± ìƒì„± ì™„ë£Œ ({tts_duration:.2f}ì´ˆ): {filename}")
                print("ë©´ì ‘ê´€: ", end="", flush=True)
                
                sentence_buffer = ""
    
    # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬
    if sentence_buffer.strip():
        tts_start = time.time()
        tts_response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=sentence_buffer.strip(),
            speed=1.0
        )
        tts_duration = time.time() - tts_start
        metrics.tts_time += tts_duration
        
        sentence_count += 1
        filename = f"method2_sentence_{sentence_count}_{int(time.time())}.mp3"
        tts_response.stream_to_file(filename)
        metrics.audio_files.append(filename)
        print(f"\n  â†’ ë¬¸ì¥ {sentence_count} ìŒì„± ìƒì„± ì™„ë£Œ ({tts_duration:.2f}ì´ˆ): {filename}")
    
    print("\n")
    metrics.total_time = time.time() - total_start
    
    metrics.print_results()
    return metrics


# ============================================================================
# ë°©ë²• 3: ë³‘ë ¬ ì²˜ë¦¬ (LLM ì™„ë£Œ í›„ ë¬¸ì¥ë³„ ë³‘ë ¬ TTS)
# ============================================================================

def method3_parallel_tts(question, voice="nova"):
    """ë°©ë²• 3: ë³‘ë ¬ ì²˜ë¦¬ - LLM ì™„ë£Œ í›„ ë¬¸ì¥ë³„ë¡œ TTS ë™ì‹œ ìƒì„±"""
    
    metrics = PerformanceMetrics("ë°©ë²• 3: ë³‘ë ¬ TTS")
    
    print(f"\n{'='*70}")
    print(f"ë°©ë²• 3: ë³‘ë ¬ TTS ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
    print(f"{'='*70}")
    print(f"ì§ˆë¬¸: {question}\n")
    
    total_start = time.time()
    
    # 1. LLM ë‹µë³€ ìƒì„±
    print("ğŸ¤– LLM ë‹µë³€ ìƒì„± ì¤‘...")
    llm_start = time.time()
    
    llm_response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": question}
        ],
        temperature=0.7,
        max_tokens=300
    )
    
    answer_text = llm_response.choices[0].message.content
    metrics.llm_time = time.time() - llm_start
    
    print(f"âœ… LLM ì™„ë£Œ ({metrics.llm_time:.2f}ì´ˆ)")
    print(f"\në©´ì ‘ê´€: {answer_text}\n")
    
    # 2. ë¬¸ì¥ ë¶„ë¦¬
    sentences = split_sentences(answer_text)
    print(f"ğŸ“ {len(sentences)}ê°œ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬\n")
    
    # 3. ê° ë¬¸ì¥ì„ ìˆœì°¨ì ìœ¼ë¡œ TTS ìƒì„± (ì‹¤ì œ ë³‘ë ¬ì€ threading í•„ìš”)
    print("ğŸ”Š ë¬¸ì¥ë³„ TTS ìƒì„± ì¤‘...")
    tts_start = time.time()
    
    for i, sentence in enumerate(sentences, 1):
        sentence_tts_start = time.time()
        
        tts_response = client.audio.speech.create(
            model="tts-1-hd",
            voice=voice,
            input=sentence,
            speed=1.0
        )
        
        sentence_tts_time = time.time() - sentence_tts_start
        
        filename = f"method3_parallel_{i}_{int(time.time())}.mp3"
        tts_response.stream_to_file(filename)
        metrics.audio_files.append(filename)
        
        if i == 1:
            metrics.first_audio_time = time.time() - total_start
        
        print(f"  [{i}/{len(sentences)}] {sentence_tts_time:.2f}ì´ˆ - {filename}")
        time.sleep(0.1)
    
    metrics.tts_time = time.time() - tts_start
    metrics.total_time = time.time() - total_start
    
    print()
    metrics.print_results()
    return metrics


# ============================================================================
# ì „ì²´ ë¹„êµ ì‹¤í–‰
# ============================================================================

def run_all_tests():
    """3ê°€ì§€ ë°©ë²• ëª¨ë‘ í…ŒìŠ¤íŠ¸í•˜ê³  ë¹„êµ"""
    
    print("\n" + "="*70)
    print("ğŸ¯ LLM + TTS í†µí•© ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("="*70)
    print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {TEST_QUESTION}")
    print(f"TTS ëª¨ë¸: tts-1-hd (ë°©ë²•1, 3), tts-1 (ë°©ë²•2)")
    print(f"TTS ëª©ì†Œë¦¬: nova")
    print("="*70)
    
    results = []
    
    # ë°©ë²• 1
    input("\n[Enterë¥¼ ëˆŒëŸ¬ ë°©ë²• 1 ì‹œì‘...]")
    result1 = method1_basic(TEST_QUESTION)
    results.append(result1)
    time.sleep(2)
    
    # ë°©ë²• 2
    input("\n[Enterë¥¼ ëˆŒëŸ¬ ë°©ë²• 2 ì‹œì‘...]")
    result2 = method2_sentence_streaming(TEST_QUESTION)
    results.append(result2)
    time.sleep(2)
    
    # ë°©ë²• 3
    input("\n[Enterë¥¼ ëˆŒëŸ¬ ë°©ë²• 3 ì‹œì‘...]")
    result3 = method3_parallel_tts(TEST_QUESTION)
    results.append(result3)
    
    # ìµœì¢… ë¹„êµ
    print("\n" + "="*70)
    print("ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ")
    print("="*70)
    print(f"{'ë°©ë²•':<20} {'ì´ ì‹œê°„':<12} {'ì²« ìŒì„±':<12} {'LLM':<10} {'TTS':<10} {'íŒŒì¼ìˆ˜':<8}")
    print("-"*70)
    
    for r in results:
        print(f"{r.method_name:<20} {r.total_time:>8.2f}ì´ˆ  {r.first_audio_time:>8.2f}ì´ˆ  "
              f"{r.llm_time:>6.2f}ì´ˆ  {r.tts_time:>6.2f}ì´ˆ  {len(r.audio_files):>4}ê°œ")
    
    print("="*70)
    
    # ì¶”ì²œ
    fastest_total = min(results, key=lambda x: x.total_time)
    fastest_first = min(results, key=lambda x: x.first_audio_time)
    
    print("\nğŸ† ì¶”ì²œ:")
    print(f"  - ê°€ì¥ ë¹ ë¥¸ ì´ ì‹œê°„:       {fastest_total.method_name}")
    print(f"  - ê°€ì¥ ë¹ ë¥¸ ì²« ìŒì„± ì‘ë‹µ:  {fastest_first.method_name}")
    print(f"\nğŸ’¡ ì‹¤ì‹œê°„ ë©´ì ‘ì—ëŠ” '{fastest_first.method_name}'ì„ ì¶”ì²œí•©ë‹ˆë‹¤!")
    print("   (ì‚¬ìš©ìê°€ ê°€ì¥ ë¹¨ë¦¬ ìŒì„±ì„ ë“¤ì„ ìˆ˜ ìˆìŒ)\n")
    
    # ìƒì„±ëœ íŒŒì¼ ì •ë¦¬
    print("ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    all_files = []
    for r in results:
        all_files.extend(r.audio_files)
    
    print(f"  ì´ {len(all_files)}ê°œ ìŒì„± íŒŒì¼ ìƒì„±")
    print("  - method1_*.mp3 : ë°©ë²• 1")
    print("  - method2_*.mp3 : ë°©ë²• 2")
    print("  - method3_*.mp3 : ë°©ë²• 3")


if __name__ == "__main__":
    run_all_tests()